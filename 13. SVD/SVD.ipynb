{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD(Singular value decomposition)\n",
    "SVD同PCA也是对数据进行降维，PCA旨在寻求最大方差来储存最多的信息，所以使用对角化让PCA后的数据协方差为对角线。不同于PCA的特征值分解，SVD利用奇异值分解，好处是不需要方阵作为输入，可以把SVD想成是非方阵的特征值分解，其中的奇异值就是特征值，选最大的几个做线性变换，我们定义SVD\n",
    "$$\n",
    "X=U\\sum V^T\n",
    "$$\n",
    "其中$U,V$是正交矩阵而$\\sum $是对角矩阵，$\\sum $对角线上的值就是$X$的奇异值\n",
    "### 优缺点\n",
    "\n",
    "优点：降低数据的复杂度、移除噪声、可能会提升模型算法精准度  \n",
    "缺点：经过转换过的数据可能难以理解\n",
    "\n",
    "\n",
    "接下来我们用代码介绍SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14142136, -0.98994949],\n",
       "       [-0.98994949,  0.14142136]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U,sigma,vT=np.linalg.svd([[1,1],[7,7]])\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.,  0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678, -0.70710678],\n",
       "       [-0.70710678,  0.70710678]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 1.],\n",
       "        [7., 7.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U*np.matrix([[10,0],[0,0]])*vT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.64365076e+00, 5.29150262e+00, 8.36478329e-16, 6.91811207e-17,\n",
       "       1.11917251e-33])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadExData():\n",
    "    return[[0, 0, 0, 2, 2],\n",
    "           [0, 0, 0, 3, 3],\n",
    "           [0, 0, 0, 1, 1],\n",
    "           [1, 1, 1, 0, 0],\n",
    "           [2, 2, 2, 0, 0],\n",
    "           [5, 5, 5, 0, 0],\n",
    "           [1, 1, 1, 0, 0]]\n",
    "data=loadExData()\n",
    "U,sigma,vT=np.linalg.svd(data)\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[9.64365076e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 5.29150262e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 8.36478329e-16]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig3=np.mat(np.eye(3)*sigma[:3,np.newaxis])\n",
    "sig3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  0.,  0.,  2.,  2.],\n",
       "        [-0.,  0.,  0.,  3.,  3.],\n",
       "        [-0.,  0.,  0.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  0.,  0.],\n",
       "        [ 2.,  2.,  2.,  0.,  0.],\n",
       "        [ 5.,  5.,  5., -0., -0.],\n",
       "        [ 1.,  1.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.rint(U[:,:3]*sig3*vT[:3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介绍完了SVD，我们要来介绍一种推荐算法-协同过滤算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12973190755680383, 1.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ecludSim(inA,inB):\n",
    "    return 1.0/(1.0 + np.linalg.norm(inA - inB))\n",
    "\n",
    "def pearsSim(inA,inB):\n",
    "    if len(inA) < 3 : return 1.0\n",
    "    return 0.5+0.5*np.corrcoef(inA, inB, rowvar = 0)[0][1]\n",
    "\n",
    "def cosSim(inA,inB):\n",
    "    num = float(inA.T*inB)\n",
    "    denom = np.linalg.norm(inA)*np.linalg.norm(inB)\n",
    "    return 0.5+0.5*(num/denom)\n",
    "data=np.mat(loadExData())\n",
    "ecludSim(data[:,0],data[:,4]),ecludSim(data[:,0],data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20596538173840329, 1.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsSim(data[:,0],data[:,4]),pearsSim(data[:,0],data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosSim(data[:,0],data[:,4]),cosSim(data[:,0],data[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用欧拉距离、皮尔森相似、余弦相似来度量item与item的相似度，接下来，我们使用餐厅菜色推荐系统来举例，推荐系统可能有如下流程：根据一位user，回传user可能会喜欢的菜色给他，在代码层面的话\n",
    "1. 先找user尚未评分的菜色\n",
    "2. 预测这些未评分的菜色user会给几分\n",
    "3. 对分数排序进行推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 4 0 2 2]\n",
      " [4 0 0 3 3]\n",
      " [4 0 0 1 1]\n",
      " [1 1 1 2 0]\n",
      " [2 2 2 0 0]\n",
      " [5 5 5 0 0]\n",
      " [1 1 1 0 0]]\n",
      "[1 2]\n",
      "the 1 and 0 similarity is: 1.000000\n",
      "the 1 and 3 similarity is: 0.928746\n",
      "the 1 and 4 similarity is: 1.000000\n",
      "the 2 and 0 similarity is: 1.000000\n",
      "the 2 and 3 similarity is: 1.000000\n",
      "the 2 and 4 similarity is: 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 2.5), (1, 2.0243290220056256)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standEst(dataMat, user, simMeas, item):\n",
    "    n = np.shape(dataMat)[1]\n",
    "    simTotal = 0.0; ratSimTotal = 0.0\n",
    "    for j in range(n):\n",
    "        userRating = dataMat[user,j]\n",
    "        if userRating == 0: continue\n",
    "        overLap = np.nonzero(np.logical_and(dataMat[:,item].A>0, \\\n",
    "                                      dataMat[:,j].A>0))[0]\n",
    "        if len(overLap) == 0: similarity = 0\n",
    "        else: similarity = simMeas(dataMat[overLap,item], \\\n",
    "                                   dataMat[overLap,j])\n",
    "        print('the %d and %d similarity is: %f' % (item, j, similarity))\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: return 0\n",
    "    else: return ratSimTotal/simTotal\n",
    "\n",
    "def recommend(dataMat, user, N=3, simMeas=cosSim, estMethod=standEst):\n",
    "    unratedItems = np.nonzero(dataMat[user,:].A==0)[1]#find unrated items \n",
    "    print(unratedItems)\n",
    "    if len(unratedItems) == 0: return 'you rated everything'\n",
    "    itemScores = []\n",
    "    for item in unratedItems:\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "        itemScores.append((item, estimatedScore))\n",
    "    return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N]\n",
    "\n",
    "data=np.mat(loadExData())\n",
    "data[0,1]=data[0,0]=data[1,0]=data[2,0]=4\n",
    "data[3,3]=2\n",
    "print(data)\n",
    "recommend(data,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们使用SVD来优化推荐系统，我们用更高维度的数据来举例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.77075346, 11.40670395, 11.03044558,  4.84639758,  3.09292055,\n",
       "        2.58097379,  1.00413543,  0.72817072,  0.43800353,  0.22082113,\n",
       "        0.07367823])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadExData2():\n",
    "    return[[0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 5],\n",
    "           [0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 3],\n",
    "           [0, 0, 0, 0, 4, 0, 0, 1, 0, 4, 0],\n",
    "           [3, 3, 4, 0, 0, 0, 0, 2, 2, 0, 0],\n",
    "           [5, 4, 5, 0, 0, 0, 0, 5, 5, 0, 0],\n",
    "           [0, 0, 0, 0, 5, 0, 1, 0, 0, 5, 0],\n",
    "           [4, 3, 4, 0, 0, 0, 0, 5, 5, 0, 1],\n",
    "           [0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 4],\n",
    "           [0, 0, 0, 2, 0, 2, 5, 0, 0, 1, 2],\n",
    "           [0, 0, 0, 0, 5, 0, 0, 0, 0, 4, 0],\n",
    "           [1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0]]\n",
    "\n",
    "U,sigma,vT=np.linalg.svd(np.mat(loadExData2()))\n",
    "sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们来找什么特征的代表性最高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541.9999999999994,\n",
       " 378.8295595113579,\n",
       " 500.5002891275791,\n",
       " 523.9878586377387,\n",
       " 533.5540161939919)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig2=sigma**2\n",
    "sum(sig2), sum(sig2[:2]),sum(sig2[:3]),sum(sig2[:4]),sum(sig2[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到前面四个属于比较重要的特征，所以我们可以将原本11维的数据降维成维数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 4 6 7 8 9]\n",
      "the 0 and 3 similarity is: 0.490950\n",
      "the 0 and 5 similarity is: 0.484274\n",
      "the 0 and 10 similarity is: 0.512755\n",
      "the 1 and 3 similarity is: 0.491294\n",
      "the 1 and 5 similarity is: 0.481516\n",
      "the 1 and 10 similarity is: 0.509709\n",
      "the 2 and 3 similarity is: 0.491573\n",
      "the 2 and 5 similarity is: 0.482346\n",
      "the 2 and 10 similarity is: 0.510584\n",
      "the 4 and 3 similarity is: 0.450495\n",
      "the 4 and 5 similarity is: 0.506795\n",
      "the 4 and 10 similarity is: 0.512896\n",
      "the 6 and 3 similarity is: 0.743699\n",
      "the 6 and 5 similarity is: 0.468366\n",
      "the 6 and 10 similarity is: 0.439465\n",
      "the 7 and 3 similarity is: 0.482175\n",
      "the 7 and 5 similarity is: 0.494716\n",
      "the 7 and 10 similarity is: 0.524970\n",
      "the 8 and 3 similarity is: 0.491307\n",
      "the 8 and 5 similarity is: 0.491228\n",
      "the 8 and 10 similarity is: 0.520290\n",
      "the 9 and 3 similarity is: 0.522379\n",
      "the 9 and 5 similarity is: 0.496130\n",
      "the 9 and 10 similarity is: 0.493617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 3.3447149384692283), (7, 3.329402072452697), (9, 3.328100876390069)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def svdEst(dataMat, user, simMeas, item):\n",
    "    n = np.shape(dataMat)[1]\n",
    "    simTotal = 0.0; ratSimTotal = 0.0\n",
    "    U,Sigma,VT = np.linalg.svd(dataMat)\n",
    "    Sig4 = np.mat(np.eye(4)*Sigma[:4]) #arrange Sig4 into a diagonal matrix\n",
    "    xformedItems = dataMat.T * U[:,:4] * Sig4.I  #create transformed items\n",
    "    for j in range(n):\n",
    "        userRating = dataMat[user,j]\n",
    "        if userRating == 0 or j==item: continue\n",
    "        similarity = simMeas(xformedItems[item,:].T,\\\n",
    "                             xformedItems[j,:].T)\n",
    "        print('the %d and %d similarity is: %f' % (item, j, similarity))\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: return 0\n",
    "    else: return ratSimTotal/simTotal\n",
    "data=np.mat(loadExData2())\n",
    "recommend(data,1,estMethod=svdEst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
